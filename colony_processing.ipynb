{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132aac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "import os\n",
    "import nd2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import stardist\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "from btrack.io import localizations_to_objects\n",
    "import btrack\n",
    "\n",
    "from skimage import io\n",
    "import skimage\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import edt\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "import ray\n",
    "import zarr\n",
    "import dask.array as da\n",
    "\n",
    "axis_norm = (0,1)\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models for stardist and CNN for nuclei classification.\n",
    "model = load_model('cnn_model_onlyintensityimage.h5')\n",
    "modelStar =  StarDist2D(None, name='stardist', basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a37fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nd2 file using a pop up window and nd2 library. \n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root= tk.Tk()\n",
    "root.wm_attributes('-topmost', True)\n",
    "path = filedialog.askopenfile()\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "nd2file = nd2.ND2File(path.name)\n",
    "viewnd2da = nd2file.to_dask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686714c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nd2 file in napari to choose position and timepoints for cropping\n",
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(viewnd2da, channel_axis=-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract channel information from metadata and assign channels to constant for channel selection later on.This is specific\n",
    "# to nd2 files.\n",
    "\n",
    "if 'GFP em' in nd2file.metadata.channels[0].channel.name:\n",
    "    for channel in nd2file.metadata.channels:\n",
    "        if 'GFP em 1' in channel.channel.name:\n",
    "            ERK = channel.channel.index\n",
    "        elif 'GFP em 2' in channel.channel.name:\n",
    "            H2B = channel.channel.index\n",
    "else:\n",
    "    for channel in nd2file.metadata.channels:\n",
    "        if 'GFP' in channel.channel.name:\n",
    "            ERK = channel.channel.index\n",
    "        elif 'Cy3' in channel.channel.name:\n",
    "            OCT = channel.channel.index\n",
    "        elif 'Cy5' in channel.channel.name:\n",
    "            H2B = channel.channel.index\n",
    "            \n",
    "#get image dimensions:\n",
    "\n",
    "Y_dim = nd2file.attributes.heightPx\n",
    "X_dim = nd2file.attributes.widthPx\n",
    "\n",
    "#get time metadata and convert to min\n",
    "\n",
    "try: t_interval = nd2file.experiment[0].parameters.periodMs/60000\n",
    "    \n",
    "except: t_interval = nd2file.experiment[0].parameters.periods[0].periodMs/60000\n",
    "        \n",
    "#select position and crop time and load into memory\n",
    "pos = 4\n",
    "volume = viewnd2da[80:500,pos,...].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skimage.filters.try_all_threshold(skimage.filters.gaussian(volume[-1,ERK,...]+volume[-1,H2B,...],sigma=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f796dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to segment colony to later exclude nuclei/debris detection not in colony. Parallelized using ray.\n",
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "\n",
    "pool=Pool()\n",
    "\n",
    "def binary_processing(image):\n",
    "\n",
    "    smooth = skimage.filters.gaussian((image[ERK] + image[H2B]) , sigma= 20)\n",
    "    \n",
    "    # using try to avoid errors when there is no thresholding possible,i.e. colony spanning over the whole field of view.\n",
    "    try: \n",
    "        tresh = skimage.filters.threshold_triangle(smooth)\n",
    "        binary = smooth  > tresh\n",
    "        binary = skimage.morphology.remove_small_objects(binary, min_size=10000)\n",
    "        binary = ndi.binary_fill_holes(binary)\n",
    "        binary = skimage.morphology.remove_small_holes(binary, area_threshold= 10000)\n",
    "        binary = skimage.morphology.binary_dilation(binary, footprint=skimage.morphology.disk(5))\n",
    "        print('binary')\n",
    "        # eroding binary to create edge binary\n",
    "        mask =  ndi.binary_erosion(binary)\n",
    "    \n",
    "        edge = binary.copy()\n",
    "    \n",
    "        # create edge image\n",
    "        edge[mask]=0   \n",
    "        edge[0,:] = 0\n",
    "        edge[:,0] = 0\n",
    "        edge[-1,:] = 0\n",
    "        edge[:,-1] = 0\n",
    "\n",
    "    except:\n",
    "        # if thresholding fails create an empty array.\n",
    "        binary=np.zeros_like(image[H2B],dtype=np.bool_)\n",
    "        edge=np.zeros_like(image[H2B],dtype=np.bool_)\n",
    "    return binary, edge\n",
    "\n",
    "results = pool.map(binary_processing, [image for image in volume])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b74e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving stacks from results\n",
    "\n",
    "binary = np.stack([result[0] for result in results])\n",
    "edge = np.stack([result[1] for result in results])\n",
    "\n",
    "# If thresholding can not be performed for all timepoints(because colony eventually spans over the whole field of view) \n",
    "# volume, binary and edge are cropt up to the last timepoint where thresholding was possible.\n",
    "\n",
    "cropt = np.argmax(np.all(binary,axis=(1,2))| np.all(~binary,axis=(1,2)))\n",
    "edge = edge[:cropt-1,...]\n",
    "binary = binary[:cropt-1,...]\n",
    "volume = volume[:cropt-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(volume, channel_axis=-3)\n",
    "viewer.add_image(binary)\n",
    "viewer.add_image(edge)\n",
    "#viewer.add_labels(distlabel)\n",
    "#viewer.add_labels(final_nuc)\n",
    "#viewer.add_labels(cyto_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb355209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## preparing images for stardist \n",
    "\n",
    "nuc_list =[]\n",
    "df=[]\n",
    "for i, image in enumerate(volume):\n",
    "    \n",
    "    #multiply H2B channel by binary image of colony to avoid segementation of cell/debris outside of the colony\n",
    "    \n",
    "    img_norm = normalize((image[H2B]), 1, 99.8, axis=axis_norm)\n",
    "    label, detail = modelStar.predict_instances(img_norm, prob_thresh=0.47)\n",
    "    \n",
    "    #multiply label by binary image of colony to remove segmentations not in the colony.\n",
    "    label = label*binary[i]\n",
    "    df_class = skimage.measure.regionprops_table(label, intensity_image=image[H2B], properties= ('label', 'intensity_image', 'area'))\n",
    "    df_class = pd.DataFrame(df_class)\n",
    "    df_class['t']=i\n",
    "    df_class['t_min']= df_class['t']*t_interval \n",
    "    #df_class['centroid-0'] =df_class['centroid-0'].astype('int')\n",
    "    #df_class['centroid-1'] =df_class['centroid-1'].astype('int')\n",
    "    \n",
    "    #preparing nuclei crops for image classification based on cell cycle state. Padding all crops to the same size.\n",
    "    \n",
    "    padarr = np.zeros((64,64), np.uint16)\n",
    "    crops =[]\n",
    "    \n",
    "    for crop in df_class.intensity_image:\n",
    "        \n",
    "        result = padarr.copy()\n",
    "        arr= crop\n",
    "        \n",
    "        xx = (64-arr.shape[1])//2\n",
    "        yy = (64-arr.shape[0])//2\n",
    "        \n",
    "        result[yy:yy+arr.shape[0], xx:xx+arr.shape[1]] = arr\n",
    "        \n",
    "        crops.append(result)\n",
    "\n",
    "    \n",
    "    images_topre = np.stack(crops)\n",
    "    images_topre = images_topre.reshape(images_topre.shape[0], images_topre.shape[1], images_topre.shape[2], 1)\n",
    "    images_topre = normalize(images_topre,1,99.8)\n",
    "    prediction = np.argmax(model.predict(images_topre), axis=-1)\n",
    "    \n",
    "    df_class['states'] = prediction.tolist()\n",
    "    #del df_class['crop']\n",
    "    del df_class['intensity_image']\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    #label = da.from_array(label)\n",
    "    nuc_list.append(label)\n",
    "    df.append(df_class)\n",
    "    print(i)\n",
    "    \n",
    "# create single 3D numpy array out of list of labels and single pandas dataframe from list\n",
    "\n",
    "final_nuc = np.stack(nuc_list)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f0a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## performing nuclear label expansion and shrinking for cyto plasma nuclear ration calculation, as well as calculation of the distance from\n",
    "## each nuclei from the colony edge using a distance map created from the edge image. Uses ray for processing over all timepoints in parallel.\n",
    "\n",
    "# creating a list of dataframes for every timepoint t\n",
    "\n",
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "pool = Pool()\n",
    "\n",
    "def process_ERK_dist(idx, i, l, e):\n",
    "\n",
    "    #creating a distance transform of the binary edge image and then finding the value for every x/y coordinate per label in the distance transform.\n",
    "    # creating a cytoplasm label.\n",
    "    cyto_label = skimage.segmentation.expand_labels(l, distance=4) - skimage.segmentation.expand_labels(l, distance=1)\n",
    "   #### shrinking nuclei for cyto/nuc ratio calculation (by Lucien Hinderling)\n",
    "    distance = 1.5\n",
    "    distances = edt.edt(l)\n",
    "    _, nearest_label_coords = distance_transform_edt(l == 0, return_indices=True)\n",
    "    shrunknuc_label = np.zeros_like(l)\n",
    "    dilate_mask = distances >= distance\n",
    "    masked_nearest_label_coords = [dimension_indices[dilate_mask] for dimension_indices in nearest_label_coords]\n",
    "    nearest_labels = l[tuple(masked_nearest_label_coords)]\n",
    "    shrunknuc_label[dilate_mask] = nearest_labels\n",
    "    ####\n",
    "    print('shrink')\n",
    "    \n",
    "    # measuring mean intensity in shrunken nuclei as well as cytoplasm \n",
    "    Meas_nuc = skimage.measure.regionprops_table(shrunknuc_label, intensity_image=i[ERK], properties= ('label', 'mean_intensity', 'centroid'))\n",
    "    Meas_cyto = skimage.measure.regionprops_table(cyto_label, intensity_image=i[ERK], properties= ('label', 'mean_intensity'))\n",
    "    Meas_OCT = skimage.measure.regionprops_table(l, intensity_image=i[OCT], properties= ('label', 'mean_intensity'))\n",
    "    Meas_H2B = skimage.measure.regionprops_table(l, intensity_image=i[H2B], properties= ('label', 'mean_intensity'))\n",
    "\n",
    "    \n",
    "    df_Meas_nuc = pd.DataFrame(Meas_nuc)\n",
    "    df_Meas_cyto = pd.DataFrame(Meas_cyto)\n",
    "    df_Meas_OCT = pd.DataFrame(Meas_OCT)\n",
    "    df_Meas_H2B = pd.DataFrame(Meas_H2B)\n",
    "    \n",
    "    df_Meas_nuc.rename(columns={'mean_intensity': 'mean_intensity_nuc'}, inplace=True)\n",
    "    df_Meas_cyto.rename(columns={'mean_intensity': 'mean_intensity_cyto'}, inplace=True)\n",
    "    df_Meas_OCT.rename(columns={'mean_intensity': 'mean_intensity_OCT'}, inplace=True)\n",
    "    df_Meas_H2B.rename(columns={'mean_intensity': 'mean_intensity_H2B'}, inplace=True)\n",
    "    #merge Dataframe and calculate Cyto/Nuc ratio\n",
    "    df_ERK_meas = pd.merge(df_Meas_nuc, df_Meas_cyto, on='label').merge(df_Meas_OCT, on='label').merge(df_Meas_H2B, on='label')\n",
    "    df_ERK_meas['CNr'] = df_ERK_meas['mean_intensity_cyto']/df_ERK_meas['mean_intensity_nuc']\n",
    "    print('finsh')\n",
    "    df_ERK_meas['t'] = idx\n",
    "    \n",
    "    df_ERK_meas.rename(columns={'centroid-0':'y', 'centroid-1':'x'}, inplace=True)\n",
    "    df_ERK_meas=df_ERK_meas.astype({'y':'uint16','x':'uint16'})\n",
    "    \n",
    "    # creating a distance transform of the binary edge image and then finding the value for every x/y coordinate per label in the distance transform.\n",
    "\n",
    "    disttrans=ndi.distance_transform_edt(e==0)\n",
    "    distances = []\n",
    "    for label in df_ERK_meas['label']:\n",
    "        dist = disttrans[df_ERK_meas[df_ERK_meas['label']==label]['y'],df_ERK_meas[df_ERK_meas['label']==label]['x']]\n",
    "        distances.append(dist[0])\n",
    "    df_ERK_meas['dist'] = distances\n",
    "    \n",
    "    return df_ERK_meas, cyto_label\n",
    " \n",
    "results = pool.starmap(process_ERK_dist, [(idx,*data) for idx,data in enumerate(zip(volume,final_nuc,edge))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8644954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting cytoplasm label array\n",
    "cyto_label = np.stack([result[1] for result in results])\n",
    "\n",
    "# extracting ERKmeasurement dataframe and merging with tracking data frame.\n",
    "\n",
    "df_ERKmeas = pd.concat([result[0] for result in results])\n",
    "df_ERKmeas = df_ERKmeas.merge(df, on=['t','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#renaming label column since 'label' in btrack is used for cell state annotation\n",
    "df_ERKmeas['label_nuc'] = df_ERKmeas['label']\n",
    "df_ERKmeas['label'] = df_ERKmeas['states']\n",
    "df_ERKmeas['states'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting dataframe to btrack oject. btrack optimizations will take too long if too many\n",
    "# tracks are identified prior of the optimization step. In my experience more than 25000 will result in excessively long \n",
    "# processing. Therefore one has to potentially reduce the time period or omit optimization and lineage tracing.\n",
    "objects_to_track = localizations_to_objects(df_ERKmeas)#[(df_tracking['t']<500) &(df_tracking['t']>50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from btrack.constants import BayesianUpdates\n",
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file('cell_config3.json')\n",
    "    \n",
    "    # use APPROXIMATE to speed up tracking\n",
    "    tracker.update_method = BayesianUpdates.APPROXIMATE\n",
    "    tracker.max_search_radius = 25\n",
    "    \n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects_to_track)\n",
    "\n",
    "    # set the volume (Z axis volume is set very large for 2D data)\n",
    "    tracker.volume=((0, X_dim), (0, Y_dim), (-1e5,1e5))\n",
    "    \n",
    "    \n",
    "    # track them (in interactive mode)\n",
    "    tracker.track()\n",
    " \n",
    "    # generate hypotheses and run the global optimizer, only required if lineage tracking is desired.\n",
    "    #tracker.optimize(options={'tm_lim': int(6e6)})\n",
    "    \n",
    "    tracks = tracker.tracks\n",
    "    \n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bf383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting tracks and combine them into a dataframe\n",
    "\n",
    "df_ERKmeas = pd.concat([pd.DataFrame(i.to_dict()) for i in tracks])\n",
    "df_ERKmeas = df_ERKmeas.reset_index(drop=True)\n",
    "# this is removing dummy objects to avoid problems with ERK cyto/nuc measurements\n",
    "df_ERKmeas.dropna(inplace=True)\n",
    "# converting the \"label_nuc\" column to \"label\" for dataframe merging.\n",
    "df_ERKmeas['label'] = df_ERKmeas.label_nuc.astype('uint')\n",
    "# deleting not needed columns\n",
    "df_ERKmeas.drop(['z'], axis=1, inplace=True)\n",
    "df_ERKmeas.drop(['label_nuc'], axis=1, inplace=True)\n",
    "df_ERKmeas.drop(['dummy'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directory for saving\n",
    "base_path = r'//izbkingston.izb.unibe.ch/imaging.data/mic01-imaging/Yannick/'\n",
    "folder = path.name.split('/')[-2]\n",
    "dest = f'{base_path}{folder}/pos{pos}/'\n",
    "\n",
    "if os.path.exists(dest):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving tracking data for napari\n",
    "\n",
    "import pickle\n",
    "with open(f'{dest}properties.pkl', 'wb') as f:\n",
    "    pickle.dump(properties, f)\n",
    "with open(f'{dest}graph.pkl', 'wb') as f:\n",
    "    pickle.dump(graph, f)\n",
    "with open(f'{dest}data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05edf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving data to csv and and labels,edge,binary, cyto_label to zarr arrays.\n",
    "df_ERKmeas.to_csv(f'{dest}EKRmeas.csv')\n",
    "\n",
    "zarr.save(f'{dest}labels.zarr', final_nuc)\n",
    "zarr.save(f'{dest}edge.zarr', edge)\n",
    "#zarr.save(f'{dest}distlabel.zarr', distlabel)\n",
    "zarr.save(f'{dest}binary.zarr', binary)\n",
    "zarr.save(f'{dest}cyto_label.zarr', cyto_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8293e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remap labels to IDs for color consistency in napari and also mapping measuruments (ERK) to segmentation. Can be used to\n",
    "# remap any data to the labels.\n",
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "df_list_t = [df_ERKmeas[df_ERKmeas['t']==t][['CNr','dist','label','ID']] for t in df_ERKmeas['t'].unique()]\n",
    "\n",
    "pool = Pool()\n",
    "\n",
    "def remap_labels(label, cyto, df_t):\n",
    "    \n",
    "    cyto = cyto.copy()\n",
    "    label = label.copy()\n",
    "    df_t=df_t.copy()\n",
    "    \n",
    "    in_map = df_t['label'].to_numpy()\n",
    "    new_map = df_t['ID'].to_numpy()\n",
    "    remap = skimage.util.map_array(label,in_map,new_map)\n",
    "    \n",
    "    in_map = df_t['label'].to_numpy()\n",
    "    new_map = df_t['ID'].to_numpy()\n",
    "    remap_cyto = skimage.util.map_array(cyto,in_map,new_map)\n",
    "\n",
    "    # for ERK remapping CNr value is multiplied by 1000 to fit a 16 bit image and save space compared to 32bit float image.\n",
    "    in_map = df_t['label'].to_numpy()\n",
    "    new_map = 1000*df_t['CNr'].to_numpy()\n",
    "    new_map = new_map.astype('uint16')\n",
    "    remapERK = skimage.util.map_array(label,in_map,new_map)\n",
    "    \n",
    "    return remap, remap_cyto, remapERK\n",
    "\n",
    "results = pool.starmap(remap_labels, [data for data in zip(final_nuc, cyto_label, df_list_t)])\n",
    "\n",
    "remap = np.stack([result[0] for result in results])\n",
    "remap_cyto = np.stack([result[1] for result in results])\n",
    "remapERK = np.stack([result[2] for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results in napari\n",
    "\n",
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(volume, channel_axis=-3)\n",
    "viewer.add_image(remapERK)\n",
    "\n",
    "viewer.add_labels(remap)\n",
    "viewer.add_labels(remap_cyto)\n",
    "\n",
    "viewer.add_image(edge)\n",
    "\n",
    "viewer.add_tracks(data=data, properties=properties, graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf07894",
   "metadata": {},
   "outputs": [],
   "source": [
    "remap = []\n",
    "for i in range(final_nuc.shape[0]):\n",
    "    in_arr = final_nuc[i].copy()\n",
    "    in_map = df_ERKmeas[df_ERKmeas['t']==i]['label'].to_numpy()\n",
    "    new_map = df_ERKmeas[df_ERKmeas['t']==i]['ID'].to_numpy()\n",
    "    remapped_ID_out = skimage.util.map_array(in_arr,in_map,new_map)\n",
    "    remap.append(remapped_ID_out)\n",
    "remap = np.stack(remap)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapcyto = []\n",
    "for i in range(cyto_label.shape[0]):\n",
    "    in_arr = cyto_label[i].copy()\n",
    "    in_map = df_ERKmeas[df_ERKmeas['t']==i]['label'].to_numpy()\n",
    "    new_map = df_ERKmeas[df_ERKmeas['t']==i]['ID'].to_numpy()\n",
    "    remapped_ID_out = skimage.util.map_array(in_arr,in_map,new_map)\n",
    "    remapcyto.append(remapped_ID_out)\n",
    "remapcyto = np.stack(remapcyto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5010b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapERK = []\n",
    "\n",
    "for i in range(final_nuc.shape[0]):\n",
    "    in_arr = final_nuc[i].copy()\n",
    "    in_map = df_ERKmeas[df_ERKmeas['t']==i]['label'].to_numpy()\n",
    "    new_map = 1000*df_ERKmeas[df_ERKmeas['t']==i]['CNr'].to_numpy()\n",
    "    new_map = new_map.astype('uint16')\n",
    "    remapped_ID_out = skimage.util.map_array(in_arr,in_map,new_map)\n",
    "    remapERK.append(remapped_ID_out)\n",
    "remapERK = np.stack(remapERK)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
